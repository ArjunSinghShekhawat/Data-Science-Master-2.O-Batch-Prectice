{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:\\Data Science 2.0 Course Prectice\\Admission_Predict.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Serial No.'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =df.iloc[:,:-1]\n",
    "y = df['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.22,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shekh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 2/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 3/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 4/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 5/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 6/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 7/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 8/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 9/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 10/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 11/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 12/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 13/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 14/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 15/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 16/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 17/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 18/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 19/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 20/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 21/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 22/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 23/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 24/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 25/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 26/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 27/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 28/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 29/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 30/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 31/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 32/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 33/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 34/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 35/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 36/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 37/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 38/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 39/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 40/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 41/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 42/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 43/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 44/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 45/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 46/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 47/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 48/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 49/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 50/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 51/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 52/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 53/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 54/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 55/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 56/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 57/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 58/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 59/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 60/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 61/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 62/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 63/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 64/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 65/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 66/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0036\n",
      "Epoch 67/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 68/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 69/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 70/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 71/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 72/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 73/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 74/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 75/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 76/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 77/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 78/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 79/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 80/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 81/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 82/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 83/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 84/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 85/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 86/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 87/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 88/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 89/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 90/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 91/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 92/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 93/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 94/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 95/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 96/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 97/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 98/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 99/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 100/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 101/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 102/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 103/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 104/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 105/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 106/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 107/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 108/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 109/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 110/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 111/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 112/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 113/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 114/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 115/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 116/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 117/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 118/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 119/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 120/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 121/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 122/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 123/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 124/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 125/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 126/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 127/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 128/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 129/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 130/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 131/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 132/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 133/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 134/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 135/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 136/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 137/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 138/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 139/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 140/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 141/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 142/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 143/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 144/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 145/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 146/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 147/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 148/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 149/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 150/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 151/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 152/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 153/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 154/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 155/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 156/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 157/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 158/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 159/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 160/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 161/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 162/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 163/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 164/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 165/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 166/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 167/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 168/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 169/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 170/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 171/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 172/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 173/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 174/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 175/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 176/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0060 - val_loss: 0.0032\n",
      "Epoch 177/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 178/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 179/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 180/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 181/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 182/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 183/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 184/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 185/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 186/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 187/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 188/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 189/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 190/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 191/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 192/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 193/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 194/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 195/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 196/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 197/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 198/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 199/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 200/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 201/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 202/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 203/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 204/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 205/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 206/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 207/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 208/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 209/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 210/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 211/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 212/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 213/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 214/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 215/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 216/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 217/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 218/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 219/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 220/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 221/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 222/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 223/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 224/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 225/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 226/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 227/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 228/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 229/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 230/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 231/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 232/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 233/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 234/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 235/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 236/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 237/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 238/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 239/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 240/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 241/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 242/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 243/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 244/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 245/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 246/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 247/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 248/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 249/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 250/250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0031\n"
     ]
    }
   ],
   "source": [
    "history  = model.fit(x_train,y_train,epochs=250,validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7008957511788294"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28e026cc590>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.008690191432833672,\n",
       "  0.008514607325196266,\n",
       "  0.008338449522852898,\n",
       "  0.00817770417779684,\n",
       "  0.008057954721152782,\n",
       "  0.007902528159320354,\n",
       "  0.007760373409837484,\n",
       "  0.007641255389899015,\n",
       "  0.007528125774115324,\n",
       "  0.00739647401496768,\n",
       "  0.007284686900675297,\n",
       "  0.007171653676778078,\n",
       "  0.007070526015013456,\n",
       "  0.0069436016492545605,\n",
       "  0.006848387885838747,\n",
       "  0.00674635823816061,\n",
       "  0.0066618286073207855,\n",
       "  0.006562001537531614,\n",
       "  0.006481526885181665,\n",
       "  0.006399749778211117,\n",
       "  0.006325067486613989,\n",
       "  0.0062432680279016495,\n",
       "  0.006181254982948303,\n",
       "  0.0061010075733065605,\n",
       "  0.006066034082323313,\n",
       "  0.005981307476758957,\n",
       "  0.005931156221777201,\n",
       "  0.005870756693184376,\n",
       "  0.005811078939586878,\n",
       "  0.005757316946983337,\n",
       "  0.005718044936656952,\n",
       "  0.0056692766956985,\n",
       "  0.005627921782433987,\n",
       "  0.005585761275142431,\n",
       "  0.005539471749216318,\n",
       "  0.005514974240213633,\n",
       "  0.005469388794153929,\n",
       "  0.005435724277049303,\n",
       "  0.005407906137406826,\n",
       "  0.005385758355259895,\n",
       "  0.00534840626642108,\n",
       "  0.005319408141076565,\n",
       "  0.005315565504133701,\n",
       "  0.005269741639494896,\n",
       "  0.005236731376498938,\n",
       "  0.005226301494985819,\n",
       "  0.005204173270612955,\n",
       "  0.005175033584237099,\n",
       "  0.005156048107892275,\n",
       "  0.005138376262038946,\n",
       "  0.005120450165122747,\n",
       "  0.005112341605126858,\n",
       "  0.00509064132347703,\n",
       "  0.005091552156955004,\n",
       "  0.0050568110309541225,\n",
       "  0.00504117039963603,\n",
       "  0.005032885819673538,\n",
       "  0.005019116215407848,\n",
       "  0.005004577804356813,\n",
       "  0.004994290880858898,\n",
       "  0.004981564357876778,\n",
       "  0.004966485779732466,\n",
       "  0.004960512276738882,\n",
       "  0.0049611288122832775,\n",
       "  0.004953297786414623,\n",
       "  0.004924242850393057,\n",
       "  0.0049162073992192745,\n",
       "  0.004927381407469511,\n",
       "  0.0048952531069517136,\n",
       "  0.004883824847638607,\n",
       "  0.004874535836279392,\n",
       "  0.0048664528876543045,\n",
       "  0.004855984356254339,\n",
       "  0.004856739193201065,\n",
       "  0.004851243924349546,\n",
       "  0.004836049396544695,\n",
       "  0.0048186639323830605,\n",
       "  0.004847740288823843,\n",
       "  0.0048105353489518166,\n",
       "  0.004802330397069454,\n",
       "  0.00479520857334137,\n",
       "  0.004778076894581318,\n",
       "  0.004778741393238306,\n",
       "  0.004780667368322611,\n",
       "  0.00476167444139719,\n",
       "  0.00477343425154686,\n",
       "  0.004765636753290892,\n",
       "  0.004749990068376064,\n",
       "  0.0047346195206046104,\n",
       "  0.004743984900414944,\n",
       "  0.004720363300293684,\n",
       "  0.004712195601314306,\n",
       "  0.004709909204393625,\n",
       "  0.004713002592325211,\n",
       "  0.004690967500209808,\n",
       "  0.004695350769907236,\n",
       "  0.004679868929088116,\n",
       "  0.004679640755057335,\n",
       "  0.004694876726716757,\n",
       "  0.0047133429907262325,\n",
       "  0.004668340086936951,\n",
       "  0.004665934015065432,\n",
       "  0.004647871945053339,\n",
       "  0.004641067236661911,\n",
       "  0.0046452064998447895,\n",
       "  0.004637344740331173,\n",
       "  0.004625688306987286,\n",
       "  0.004617960192263126,\n",
       "  0.004617346916347742,\n",
       "  0.004615585785359144,\n",
       "  0.004597946535795927,\n",
       "  0.0046248724684119225,\n",
       "  0.004589098505675793,\n",
       "  0.004594951402395964,\n",
       "  0.00459230737760663,\n",
       "  0.004579655360430479,\n",
       "  0.004582766443490982,\n",
       "  0.004565935116261244,\n",
       "  0.004575008526444435,\n",
       "  0.004556469153612852,\n",
       "  0.004550354089587927,\n",
       "  0.004550015088170767,\n",
       "  0.0045511373318731785,\n",
       "  0.004541435278952122,\n",
       "  0.004535734187811613,\n",
       "  0.004544861149042845,\n",
       "  0.004555447958409786,\n",
       "  0.004517300054430962,\n",
       "  0.004517114721238613,\n",
       "  0.004521973431110382,\n",
       "  0.0045109582133591175,\n",
       "  0.004501963034272194,\n",
       "  0.00450217816978693,\n",
       "  0.004492518492043018,\n",
       "  0.0044972263276577,\n",
       "  0.004516902379691601,\n",
       "  0.004501554649323225,\n",
       "  0.004488780628889799,\n",
       "  0.004476954694837332,\n",
       "  0.004477904178202152,\n",
       "  0.004482403863221407,\n",
       "  0.004475095309317112,\n",
       "  0.004456445574760437,\n",
       "  0.004469015169888735,\n",
       "  0.004454529844224453,\n",
       "  0.004449682310223579,\n",
       "  0.004446179606020451,\n",
       "  0.0044571105390787125,\n",
       "  0.00445135310292244,\n",
       "  0.004432708956301212,\n",
       "  0.004493621177971363,\n",
       "  0.0044355918653309345,\n",
       "  0.004441870376467705,\n",
       "  0.0044375876896083355,\n",
       "  0.00442200992256403,\n",
       "  0.0044336686842143536,\n",
       "  0.004441510885953903,\n",
       "  0.004409493412822485,\n",
       "  0.004422465339303017,\n",
       "  0.004405854269862175,\n",
       "  0.004418358206748962,\n",
       "  0.004397406708449125,\n",
       "  0.004392859060317278,\n",
       "  0.0044062440283596516,\n",
       "  0.004390497226268053,\n",
       "  0.004388723988085985,\n",
       "  0.004380356520414352,\n",
       "  0.0043968637473881245,\n",
       "  0.004393825773149729,\n",
       "  0.00437718303874135,\n",
       "  0.004375030752271414,\n",
       "  0.004377528093755245,\n",
       "  0.00436766492202878,\n",
       "  0.0043702865950763226,\n",
       "  0.004366070963442326,\n",
       "  0.00437367195263505,\n",
       "  0.004351687617599964,\n",
       "  0.004357450641691685,\n",
       "  0.004346719477325678,\n",
       "  0.004355272743850946,\n",
       "  0.004345014691352844,\n",
       "  0.0043448698706924915,\n",
       "  0.004343739245086908,\n",
       "  0.004334368277341127,\n",
       "  0.004337646998465061,\n",
       "  0.00432807020843029,\n",
       "  0.004337820690125227,\n",
       "  0.004328392446041107,\n",
       "  0.004325187299400568,\n",
       "  0.00431825639680028,\n",
       "  0.004323632922023535,\n",
       "  0.004335314501076937,\n",
       "  0.004319311585277319,\n",
       "  0.004317261278629303,\n",
       "  0.0043189190328121185,\n",
       "  0.004318071994930506,\n",
       "  0.004316937178373337,\n",
       "  0.004304820671677589,\n",
       "  0.004294876474887133,\n",
       "  0.004308883100748062,\n",
       "  0.004352142568677664,\n",
       "  0.004290140699595213,\n",
       "  0.004328381270170212,\n",
       "  0.004288453608751297,\n",
       "  0.004297997802495956,\n",
       "  0.0042814649641513824,\n",
       "  0.004283496178686619,\n",
       "  0.004287706222385168,\n",
       "  0.004275350831449032,\n",
       "  0.004297630395740271,\n",
       "  0.004274089355021715,\n",
       "  0.004277562256902456,\n",
       "  0.004270179662853479,\n",
       "  0.004267141688615084,\n",
       "  0.004283234942704439,\n",
       "  0.004348604008555412,\n",
       "  0.0042573739774525166,\n",
       "  0.004293611738830805,\n",
       "  0.004339270759373903,\n",
       "  0.004279567394405603,\n",
       "  0.004265748430043459,\n",
       "  0.004268841817975044,\n",
       "  0.004249559249728918,\n",
       "  0.004274644888937473,\n",
       "  0.004334366414695978,\n",
       "  0.004254691302776337,\n",
       "  0.004252021200954914,\n",
       "  0.004267375450581312,\n",
       "  0.004245199728757143,\n",
       "  0.004249262157827616,\n",
       "  0.004270726814866066,\n",
       "  0.004268223885446787,\n",
       "  0.004242095164954662,\n",
       "  0.004238521680235863,\n",
       "  0.0042497869580984116,\n",
       "  0.0042307437397539616,\n",
       "  0.004268251825124025,\n",
       "  0.00422205263748765,\n",
       "  0.0042334930039942265,\n",
       "  0.004227490164339542,\n",
       "  0.004247008822858334,\n",
       "  0.004226956982165575,\n",
       "  0.004230910912156105,\n",
       "  0.004226196091622114,\n",
       "  0.004222847055643797,\n",
       "  0.004236076958477497,\n",
       "  0.004217112902551889,\n",
       "  0.004223297815769911,\n",
       "  0.0042234244756400585,\n",
       "  0.00422314228489995],\n",
       " 'val_loss': [0.007279981859028339,\n",
       "  0.0071050263941287994,\n",
       "  0.006951791699975729,\n",
       "  0.006811573635786772,\n",
       "  0.0066332523711025715,\n",
       "  0.006520668510347605,\n",
       "  0.006435159128159285,\n",
       "  0.006328608375042677,\n",
       "  0.006191187538206577,\n",
       "  0.006085386499762535,\n",
       "  0.006011949386447668,\n",
       "  0.005839549470692873,\n",
       "  0.0056847091764211655,\n",
       "  0.005653953645378351,\n",
       "  0.0055748093873262405,\n",
       "  0.005503532011061907,\n",
       "  0.005375928245484829,\n",
       "  0.0052659218199551105,\n",
       "  0.005172522272914648,\n",
       "  0.0050805797800421715,\n",
       "  0.005037643015384674,\n",
       "  0.0049742949195206165,\n",
       "  0.004877503961324692,\n",
       "  0.004845708142966032,\n",
       "  0.0047376942820847034,\n",
       "  0.004765487741678953,\n",
       "  0.004685457795858383,\n",
       "  0.00456387922167778,\n",
       "  0.004496759735047817,\n",
       "  0.0044830660335719585,\n",
       "  0.004468886647373438,\n",
       "  0.0044074770994484425,\n",
       "  0.004321012180298567,\n",
       "  0.004315792582929134,\n",
       "  0.0042480886913836,\n",
       "  0.00416660588234663,\n",
       "  0.004184106830507517,\n",
       "  0.004199440591037273,\n",
       "  0.004120202269405127,\n",
       "  0.004149970598518848,\n",
       "  0.004041796084493399,\n",
       "  0.0040062000043690205,\n",
       "  0.004052721429616213,\n",
       "  0.004002375528216362,\n",
       "  0.003918381407856941,\n",
       "  0.0038925569970160723,\n",
       "  0.0039076735265553,\n",
       "  0.0038834407459944487,\n",
       "  0.0038724886253476143,\n",
       "  0.0038763051852583885,\n",
       "  0.003866477869451046,\n",
       "  0.0038091123569756746,\n",
       "  0.0038182942662388086,\n",
       "  0.003861089935526252,\n",
       "  0.0037797116674482822,\n",
       "  0.003741349559277296,\n",
       "  0.0037445349153131247,\n",
       "  0.0037370570935308933,\n",
       "  0.003767529735341668,\n",
       "  0.003721439279615879,\n",
       "  0.0037138769403100014,\n",
       "  0.003690435318276286,\n",
       "  0.0036733730230480433,\n",
       "  0.0037051953841000795,\n",
       "  0.003686364972963929,\n",
       "  0.003606001380831003,\n",
       "  0.003618543967604637,\n",
       "  0.003676564898341894,\n",
       "  0.003629484912380576,\n",
       "  0.0036269365809857845,\n",
       "  0.0036282772198319435,\n",
       "  0.0036094265524297953,\n",
       "  0.0036052416544407606,\n",
       "  0.003612057538703084,\n",
       "  0.0035621130373328924,\n",
       "  0.0035546759609133005,\n",
       "  0.0035754009149968624,\n",
       "  0.0036475618835538626,\n",
       "  0.0035284189507365227,\n",
       "  0.00351975136436522,\n",
       "  0.0035284992773085833,\n",
       "  0.0035970716271549463,\n",
       "  0.0035671687219291925,\n",
       "  0.0035708281211555004,\n",
       "  0.003515705931931734,\n",
       "  0.003436512779444456,\n",
       "  0.003527282737195492,\n",
       "  0.0035540650133043528,\n",
       "  0.003501956583932042,\n",
       "  0.0034485426731407642,\n",
       "  0.0034748362377285957,\n",
       "  0.003515237243846059,\n",
       "  0.0035411010030657053,\n",
       "  0.003456828650087118,\n",
       "  0.0034704944118857384,\n",
       "  0.0035199220292270184,\n",
       "  0.0034677612129598856,\n",
       "  0.0034040033351629972,\n",
       "  0.0034869175869971514,\n",
       "  0.0033777381759136915,\n",
       "  0.003462517634034157,\n",
       "  0.003490528091788292,\n",
       "  0.0033873256761580706,\n",
       "  0.003397664288058877,\n",
       "  0.0034573706798255444,\n",
       "  0.0034559492487460375,\n",
       "  0.0034020741004496813,\n",
       "  0.0034146024845540524,\n",
       "  0.0034183613024652004,\n",
       "  0.0033681648783385754,\n",
       "  0.003399880137294531,\n",
       "  0.0034989581909030676,\n",
       "  0.003381984308362007,\n",
       "  0.003354246262460947,\n",
       "  0.0033607888035476208,\n",
       "  0.0033749251160770655,\n",
       "  0.0033509547356516123,\n",
       "  0.00338526489213109,\n",
       "  0.0033592768013477325,\n",
       "  0.0033965555485337973,\n",
       "  0.0033891883213073015,\n",
       "  0.0033451251219958067,\n",
       "  0.0033615785650908947,\n",
       "  0.0033627101220190525,\n",
       "  0.00330166588537395,\n",
       "  0.0033156555145978928,\n",
       "  0.003365403274074197,\n",
       "  0.0033024409785866737,\n",
       "  0.003296446055173874,\n",
       "  0.0033362838439643383,\n",
       "  0.0033074552193284035,\n",
       "  0.003348524682223797,\n",
       "  0.0033131639938801527,\n",
       "  0.0033309042919427156,\n",
       "  0.003359363414347172,\n",
       "  0.00324991624802351,\n",
       "  0.0033327662386000156,\n",
       "  0.0033201586920768023,\n",
       "  0.003295627888292074,\n",
       "  0.0032649158965796232,\n",
       "  0.0032697159331291914,\n",
       "  0.0032458121422678232,\n",
       "  0.0033334577456116676,\n",
       "  0.003362904069945216,\n",
       "  0.0032607808243483305,\n",
       "  0.0032691506203264,\n",
       "  0.003244516672566533,\n",
       "  0.0032762784976512194,\n",
       "  0.003269241424277425,\n",
       "  0.0032651203218847513,\n",
       "  0.003389341989532113,\n",
       "  0.003197434125468135,\n",
       "  0.003232263959944248,\n",
       "  0.0032739934977144003,\n",
       "  0.00326443905942142,\n",
       "  0.003307508071884513,\n",
       "  0.0031818896532058716,\n",
       "  0.0032400081399828196,\n",
       "  0.0033147046342492104,\n",
       "  0.0032190964557230473,\n",
       "  0.0032053671311587095,\n",
       "  0.003264885162934661,\n",
       "  0.003255927935242653,\n",
       "  0.0031830319203436375,\n",
       "  0.00324632809497416,\n",
       "  0.0032611307688057423,\n",
       "  0.0032290995586663485,\n",
       "  0.0031619947403669357,\n",
       "  0.003294747555628419,\n",
       "  0.0032058926299214363,\n",
       "  0.0031822146847844124,\n",
       "  0.003230397356674075,\n",
       "  0.0031851225066930056,\n",
       "  0.0032073420006781816,\n",
       "  0.003238147357478738,\n",
       "  0.0032459853682667017,\n",
       "  0.003150378819555044,\n",
       "  0.0031811241060495377,\n",
       "  0.0032143990974873304,\n",
       "  0.0032526724971830845,\n",
       "  0.003163367509841919,\n",
       "  0.0031749866902828217,\n",
       "  0.003173885401338339,\n",
       "  0.0032712072134017944,\n",
       "  0.003240099409595132,\n",
       "  0.003153344849124551,\n",
       "  0.0031843860633671284,\n",
       "  0.003165471600368619,\n",
       "  0.0031690539326518774,\n",
       "  0.003177254693582654,\n",
       "  0.003236178308725357,\n",
       "  0.0031987675465643406,\n",
       "  0.003145424881950021,\n",
       "  0.003171999240294099,\n",
       "  0.0031980834901332855,\n",
       "  0.0031587916892021894,\n",
       "  0.003143847221508622,\n",
       "  0.003139510750770569,\n",
       "  0.0031883923802524805,\n",
       "  0.0032289589289575815,\n",
       "  0.0030929914209991693,\n",
       "  0.0032066504936665297,\n",
       "  0.0032707643695175648,\n",
       "  0.0031003919430077076,\n",
       "  0.003107424359768629,\n",
       "  0.0031803010497242212,\n",
       "  0.003181263105943799,\n",
       "  0.0031986599788069725,\n",
       "  0.003113997634500265,\n",
       "  0.003136229468509555,\n",
       "  0.0031286829616874456,\n",
       "  0.0031684855930507183,\n",
       "  0.0031327989418059587,\n",
       "  0.003106545889750123,\n",
       "  0.0031520442571491003,\n",
       "  0.003082010895013809,\n",
       "  0.0031731913331896067,\n",
       "  0.003248065710067749,\n",
       "  0.0030265995301306248,\n",
       "  0.00318674324080348,\n",
       "  0.003135587088763714,\n",
       "  0.003155169077217579,\n",
       "  0.0030761612579226494,\n",
       "  0.0030493997037410736,\n",
       "  0.0032663303427398205,\n",
       "  0.0030782900284975767,\n",
       "  0.003029771614819765,\n",
       "  0.003097770269960165,\n",
       "  0.0031500558834522963,\n",
       "  0.0031493029091507196,\n",
       "  0.003044256940484047,\n",
       "  0.003193514421582222,\n",
       "  0.003124765120446682,\n",
       "  0.003038995433598757,\n",
       "  0.003110740799456835,\n",
       "  0.003152420511469245,\n",
       "  0.0031304368749260902,\n",
       "  0.003065919503569603,\n",
       "  0.0030871646013110876,\n",
       "  0.003092630999162793,\n",
       "  0.003150958800688386,\n",
       "  0.003072042018175125,\n",
       "  0.0030677486211061478,\n",
       "  0.00315173645503819,\n",
       "  0.003107846714556217,\n",
       "  0.003061666153371334,\n",
       "  0.0031090076081454754,\n",
       "  0.003125710180029273,\n",
       "  0.003080432303249836,\n",
       "  0.0030708767008036375]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
